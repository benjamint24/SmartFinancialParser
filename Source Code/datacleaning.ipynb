{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "d5267d71-bafe-4d91-9035-39f4c7d17d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total raw rows:       1000\n",
      "Rows kept:            1000\n",
      "Date parse errors:    0\n",
      "Amount parse errors:  0\n",
      "Unmapped merchants:   0\n",
      "Unique merchants (27):\n",
      "   AIRBNB\n",
      "   AMAZON\n",
      "   APPLE\n",
      "   BEST BUY\n",
      "   CAR WASH PRO\n",
      "   CHIPOTLE\n",
      "   CITY UTILITIES\n",
      "   COSTCO\n",
      "   DOORDASH\n",
      "   GOOGLE\n",
      "   GYM MEMBERSHIP\n",
      "   HOME DEPOT\n",
      "   INSTACART\n",
      "   LOWE'S\n",
      "   LYFT\n",
      "   MACY'S\n",
      "   MCDONALDS\n",
      "   NETFLIX\n",
      "   OLIVE GARDEN\n",
      "   PANDA EXPRESS\n",
      "   SHELL\n",
      "   SPOTIFY\n",
      "   STARBUCKS\n",
      "   SUSHI HOUSE\n",
      "   TARGET\n",
      "   UBER\n",
      "   WALMART\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "# input/output files\n",
    "INPUT_FILE = \"../datasets/synthetic_transactions.csv\"\n",
    "OUTPUT_FILE = \"../datasets/synthetic_transactions_clean.csv\"\n",
    "\n",
    "# merchants match my base merchants from data creation\n",
    "BASE_MERCHANTS = {\n",
    "    #first 16 should all map to the key\n",
    "    \"UBER\": [\"UBER\", \"Uber\", \"Uber Technologies\", \"UBER EATS\", \"UBER *TRIP\"],\n",
    "    \"STARBUCKS\": [\"Starbucks\", \"STARBUCKS\", \"Starbucks Coffee\"],\n",
    "    \"AMAZON\": [\"Amazon\", \"AMZN\", \"Amazon Marketplace\"],\n",
    "    \"WALMART\": [\"Walmart\", \"WAL-MART\", \"Walmart Supercenter\"],\n",
    "    \"TARGET\": [\"Target\", \"TARGET\", \"Target Store\"],\n",
    "    \"MCDONALDS\": [\"McDonalds\", \"McDonald's\", \"MCD\"],\n",
    "    \"SHELL\": [\"Shell\", \"Shell Oil\", \"SHELL GAS\"],\n",
    "    \"LYFT\": [\"Lyft\", \"LYFT RIDE\"],\n",
    "    \"SPOTIFY\": [\"Spotify\", \"SPOTIFY\", \"Spotify Pmnt\"],\n",
    "    \"NETFLIX\": [\"Netflix\", \"NETFLIX\", \"Netflix.com\"],\n",
    "    \"APPLE\": [\"Apple\", \"APPLE.COM/BILL\", \"Apple Services\"],\n",
    "    \"GOOGLE\": [\"Google\", \"GOOGLE *SERVICES\", \"Google Play\"],\n",
    "    \"DOORDASH\": [\"DoorDash\", \"DOORDASH\", \"DOORDASH*ORDER\"],\n",
    "    \"INSTACART\": [\"Instacart\", \"INSTACART\"],\n",
    "    \"AIRBNB\": [\"Airbnb\", \"AIRBNB\", \"AIRBNB PAY\"],\n",
    "    \"COSTCO\": [\"Costco\", \"COSTCO WHOLESALE\"],\n",
    "    \n",
    "    #last three should just map to the name in the end\n",
    "    \n",
    "    # Restaurants\n",
    "    \"OLIVE_GARDEN\": [\"Olive Garden\"],\n",
    "    \"CHIPOTLE\": [\"Chipotle\"],\n",
    "    \"PANDA_EXPRESS\": [\"Panda Express\"],\n",
    "    \"SUSHI_HOUSE\": [\"Sushi House\"],\n",
    "\n",
    "    # Retail\n",
    "    \"BEST_BUY\": [\"Best Buy\"],\n",
    "    \"HOME_DEPOT\": [\"Home Depot\"],\n",
    "    \"LOWES\": [\"LOWE'S\"],\n",
    "    \"MACYS\": [\"Macy's\"],\n",
    "\n",
    "    # Service\n",
    "    \"CITY_UTILITIES\": [\"City Utilities\"],\n",
    "    \"GYM_MEMBERSHIP\": [\"Gym Membership\"],\n",
    "    \"CAR_WASH_PRO\": [\"Car Wash Pro\"],\n",
    "}\n",
    "\n",
    "\n",
    "# Date parsing and normalization\n",
    "# -----------------------------\n",
    "\n",
    "DATE_PATTERNS = [\n",
    "    \"%Y-%m-%d\",   # 2021-6-7 or 2021-06-07\n",
    "    \"%m/%d/%Y\",   # 6/7/2021 or 06/07/2021\n",
    "    \"%b %d %Y\",   # Jun 7 2021 or Jun 07 2021\n",
    "    \"%d-%m-%y\",   # 7-6-21 or 07-06-21\n",
    "    \"%d %b %y\",   # 7 Jun 21\n",
    "    \"%d %b %Y\",   # 7 Jun 2021\n",
    "]\n",
    " \n",
    "#regex using re that takes care of all MMM DD+suffix YY formats \n",
    "''' HAS to have (in order)\n",
    "        -starting (^) with three alphabetic characters mixed case allowed : (?P<mon>[A-Za-z]{3})\n",
    "        -1 more more spaces : \\s+\n",
    "        -date with one or two digits: (?P<day>\\d{1,2})\n",
    "        -required suffix right after: (st|nd|rd|th)\n",
    "        -1 more more spaces : \\s+\n",
    "        -year with 2 digits : (?P<year>\\d{2})\n",
    "        -NOTHING after: $\n",
    "\n",
    "    Example cases:\n",
    "        Jan 1st 21\n",
    "        Oct 23rd 19\n",
    "        Feb 07th 05\n",
    "        mAr 3rd 24\n",
    "        Apr   9th    17\n",
    "'''   \n",
    "_suffix_date_regex = re.compile(\n",
    "    \n",
    "    r\"^(?P<mon>[A-Za-z]{3})\\s+(?P<day>\\d{1,2})(st|nd|rd|th)\\s+(?P<year>\\d{2})$\"\n",
    ")\n",
    "\n",
    "# parse data with with datetime's dt which can automatically format all the other formats except for MMM Dth YY\n",
    "def parse_date(raw: str) -> Optional[str]:\n",
    "    s = str(raw).strip()\n",
    "\n",
    "    # Try all direct patterns first\n",
    "    for pattern in DATE_PATTERNS:\n",
    "        try:\n",
    "            dt = datetime.strptime(s, pattern)\n",
    "            return dt.date().isoformat()  # YYYY-MM-DD\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    # use regex to handle mmm dth yy\n",
    "\n",
    "    #match handles different starts\n",
    "    m = _suffix_date_regex.match(s)\n",
    "    if m:\n",
    "        #convert to valid datetime format to get ready to convert\n",
    "        mon_str = m.group(\"mon\")\n",
    "        day = int(m.group(\"day\"))\n",
    "        year_short = int(m.group(\"year\"))\n",
    "\n",
    "        year_full = 2000 + year_short\n",
    "\n",
    "        #convert to datetime\n",
    "        try:\n",
    "            dt = datetime.strptime(f\"{mon_str} {day} {year_full}\", \"%b %d %Y\")\n",
    "            return dt.date().isoformat()\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "# Merchant normalization (27 uniques)\n",
    "# -------------------------------------\n",
    "\n",
    "# Canonical form for matching: uppercase and strip non-alphanumeric\n",
    "def _canonical_string(s: str) -> str:\n",
    "    return re.sub(r\"[^A-Z0-9]\", \"\", s.upper())\n",
    "\n",
    "\n",
    "# related to these should collpase to one of these 16\n",
    "BRAND_KEYS = {\n",
    "    \"UBER\",\n",
    "    \"STARBUCKS\",\n",
    "    \"AMAZON\",\n",
    "    \"WALMART\",\n",
    "    \"TARGET\",\n",
    "    \"MCDONALDS\",\n",
    "    \"SHELL\",\n",
    "    \"LYFT\",\n",
    "    \"SPOTIFY\",\n",
    "    \"NETFLIX\",\n",
    "    \"APPLE\",\n",
    "    \"GOOGLE\",\n",
    "    \"DOORDASH\",\n",
    "    \"INSTACART\",\n",
    "    \"AIRBNB\",\n",
    "    \"COSTCO\",\n",
    "}\n",
    "\n",
    "# Build (canonical_base, canonical_output) pairs:\n",
    "# - If family in BRAND_KEYS -> output key\n",
    "# - IF restaurants/retail/service -> output original name\n",
    "CANONICAL_BASES = []\n",
    "for family, names in BASE_MERCHANTS.items():\n",
    "    if family in BRAND_KEYS:\n",
    "        canonical_output = family          \n",
    "    else:\n",
    "        canonical_output = names[0]      \n",
    "\n",
    "    for base in names:\n",
    "        canon = _canonical_string(base)\n",
    "        if not canon:\n",
    "            continue\n",
    "        CANONICAL_BASES.append((canon, canonical_output.upper()))\n",
    "\n",
    "# Matches based on spelling errors using edit distance algorithm\n",
    "def levenshtein(a: str, b: str) -> int:\n",
    "    \"\"\"Plain edit distance.\"\"\"\n",
    "    if a == b:\n",
    "        return 0\n",
    "    if not a:\n",
    "        return len(b)\n",
    "    if not b:\n",
    "        return len(a)\n",
    "    prev = list(range(len(b) + 1))\n",
    "    for i, ca in enumerate(a, start=1):\n",
    "        cur = [i]\n",
    "        for j, cb in enumerate(b, start=1):\n",
    "            ins = cur[j - 1] + 1\n",
    "            delete = prev[j] + 1\n",
    "            sub = prev[j - 1] + (ca != cb)\n",
    "            cur.append(min(ins, delete, sub))\n",
    "        prev = cur\n",
    "    return prev[-1]\n",
    "\n",
    "\n",
    "def clean_merchant(raw: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns cleaned merchant name.\n",
    "    If it cannot be mapped, returns the string \"ERROR\".\n",
    "    \"\"\"\n",
    "\n",
    "    s = str(raw).strip()\n",
    "    \n",
    "    if not s:\n",
    "        return \"ERROR\"\n",
    "\n",
    "    #uses cleaner regex funciton from earlier\n",
    "    canon_input = _canonical_string(s)\n",
    "    \n",
    "    if not canon_input:\n",
    "        return \"ERROR\"\n",
    "\n",
    "    # 1) Substring heuristic (prefer the longest match)\n",
    "    best_match = None\n",
    "    best_len = 0\n",
    "    for canon_base, canonical_output in CANONICAL_BASES:\n",
    "        if canon_base in canon_input and len(canon_base) > best_len:\n",
    "            best_len = len(canon_base)\n",
    "            best_match = canonical_output\n",
    "\n",
    "    if best_match is not None:\n",
    "        return best_match\n",
    "\n",
    "    # 2) Fuzzy fallback (for heavy typos like \"LmFT\", \"ACrbnb\", etc.)\n",
    "    best_dist = 10**9\n",
    "    best = None\n",
    "    for canon_base, canonical_output in CANONICAL_BASES:\n",
    "        dist = levenshtein(canon_input, canon_base)\n",
    "        if dist < best_dist:\n",
    "            best_dist = dist\n",
    "            best = canonical_output\n",
    "\n",
    "    if best is not None:\n",
    "        return best\n",
    "\n",
    "    # Final fallback â€” nothing matched\n",
    "    return \"ERROR\"\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Amount normalization, one functions\n",
    "# ---------------------\n",
    "\n",
    "# converts messy amounts and returns into 2 decimal format\n",
    "def parse_amount(raw: str) -> Optional[str]:\n",
    "\n",
    "    #leading and trailing spaces\n",
    "    s = str(raw).strip()\n",
    "\n",
    "\n",
    "    # Remove USD (rusing regex to match usd at beginning end and with mixed cases), $, and commas\n",
    "    s = re.sub(r\"(?i)usd\", \"\", s)\n",
    "    s = s.replace(\"$\", \"\").replace(\",\", \"\")\n",
    "    s = s.strip()\n",
    "\n",
    "    #convert to float with two decimals\n",
    "    return f\"{float(s):.2f}\" if s else None\n",
    "\n",
    "# ============================================================\n",
    "# Main cleaning pipeline\n",
    "# ============================================================\n",
    "\n",
    "def clean_csv() -> Dict[str, object]:\n",
    "    cleaned_rows: List[Dict[str, str]] = []\n",
    "    date_errors = 0\n",
    "    amount_errors = 0\n",
    "    merchant_unmapped = 0\n",
    "    total_rows = 0\n",
    "\n",
    "    with open(INPUT_FILE, mode=\"r\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            total_rows += 1\n",
    "\n",
    "            raw_date = row.get(\"date\", \"\")\n",
    "            raw_merchant = row.get(\"merchant\", \"\")\n",
    "            raw_amount = row.get(\"amount\", \"\")\n",
    "\n",
    "            clean_date = parse_date(raw_date)\n",
    "            clean_amount = parse_amount(raw_amount)\n",
    "            clean_merchant_val = clean_merchant(raw_merchant)\n",
    "\n",
    "            if clean_date is None:\n",
    "                date_errors += 1\n",
    "                # If you want to keep rows with bad dates, change this `continue`\n",
    "                continue\n",
    "\n",
    "            if clean_amount is None:\n",
    "                amount_errors += 1\n",
    "                # Same here if you want to keep them\n",
    "                continue\n",
    "\n",
    "  \n",
    "\n",
    "            if clean_merchant_val == \"ERROR\":\n",
    "                merchant_unmapped += 1\n",
    "\n",
    "            cleaned_rows.append(\n",
    "                {\n",
    "                    \"date\": clean_date,\n",
    "                    \"merchant\": clean_merchant_val,\n",
    "                    \"amount\": clean_amount,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # Write cleaned CSV\n",
    "    with open(OUTPUT_FILE, mode=\"w\", newline=\"\", encoding=\"utf-8\") as f_out:\n",
    "        writer = csv.DictWriter(f_out, fieldnames=[\"date\", \"merchant\", \"amount\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(cleaned_rows)\n",
    "\n",
    "    return {\n",
    "        \"cleaned_rows\": cleaned_rows,\n",
    "        \"total_rows\": total_rows,\n",
    "        \"date_errors\": date_errors,\n",
    "        \"amount_errors\": amount_errors,\n",
    "        \"merchant_unmapped\": merchant_unmapped,\n",
    "    }\n",
    "\n",
    "\n",
    "def main():\n",
    "    result = clean_csv()\n",
    "\n",
    "    cleaned_rows = result[\"cleaned_rows\"]\n",
    "    total_rows = result[\"total_rows\"]\n",
    "    date_errors = result[\"date_errors\"]\n",
    "    amount_errors = result[\"amount_errors\"]\n",
    "    merchant_unmapped = result[\"merchant_unmapped\"]\n",
    "\n",
    "    print(f\"Total raw rows:       {total_rows}\")\n",
    "    print(f\"Rows kept:            {len(cleaned_rows)}\")\n",
    "    print(f\"Date parse errors:    {date_errors}\")\n",
    "    print(f\"Amount parse errors:  {amount_errors}\")\n",
    "    print(f\"Unmapped merchants:   {merchant_unmapped}\")\n",
    "\n",
    "    unique_merchants = sorted(set(r[\"merchant\"] for r in cleaned_rows))\n",
    "    print(f\"Unique merchants ({len(unique_merchants)}):\")\n",
    "    for m in unique_merchants:\n",
    "        print(\"  \", m)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "cd912e25-02a2-4027-8cb9-45663e30e6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>merchant</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-26</td>\n",
       "      <td>AMAZON</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-08-11</td>\n",
       "      <td>STARBUCKS</td>\n",
       "      <td>2395.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-09</td>\n",
       "      <td>AIRBNB</td>\n",
       "      <td>1053.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-09-22</td>\n",
       "      <td>SHELL</td>\n",
       "      <td>1698.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-19</td>\n",
       "      <td>DOORDASH</td>\n",
       "      <td>1613.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   merchant   amount\n",
       "0  2021-09-26     AMAZON     1.00\n",
       "1  2024-08-11  STARBUCKS  2395.00\n",
       "2  2025-01-09     AIRBNB  1053.93\n",
       "3  2019-09-22      SHELL  1698.42\n",
       "4  2020-01-19   DOORDASH  1613.00"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(OUTPUT_FILE)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "3b431942-8a24-437f-b3fb-d83dd8295d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['merchant'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "3ee1629c-ecb6-4bd0-b304-d1f47e89c643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>merchant</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-26</td>\n",
       "      <td>AMAZON</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-08-11</td>\n",
       "      <td>STARBUCKS</td>\n",
       "      <td>2395.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-09</td>\n",
       "      <td>AIRBNB</td>\n",
       "      <td>1053.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-09-22</td>\n",
       "      <td>SHELL</td>\n",
       "      <td>1698.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-19</td>\n",
       "      <td>DOORDASH</td>\n",
       "      <td>1613.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-07-06</td>\n",
       "      <td>SHELL</td>\n",
       "      <td>2465.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-11-26</td>\n",
       "      <td>AMAZON</td>\n",
       "      <td>276.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-07-04</td>\n",
       "      <td>CAR WASH PRO</td>\n",
       "      <td>311.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-07-29</td>\n",
       "      <td>GOOGLE</td>\n",
       "      <td>434.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-07-15</td>\n",
       "      <td>DOORDASH</td>\n",
       "      <td>2036.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-10-09</td>\n",
       "      <td>TARGET</td>\n",
       "      <td>907.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-09-14</td>\n",
       "      <td>SPOTIFY</td>\n",
       "      <td>1842.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-11-03</td>\n",
       "      <td>DOORDASH</td>\n",
       "      <td>482.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2024-08-22</td>\n",
       "      <td>LYFT</td>\n",
       "      <td>998.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2025-02-08</td>\n",
       "      <td>DOORDASH</td>\n",
       "      <td>470.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>INSTACART</td>\n",
       "      <td>775.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021-06-22</td>\n",
       "      <td>TARGET</td>\n",
       "      <td>2249.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>AIRBNB</td>\n",
       "      <td>1143.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2024-02-12</td>\n",
       "      <td>APPLE</td>\n",
       "      <td>1951.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>WALMART</td>\n",
       "      <td>900.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2021-03-23</td>\n",
       "      <td>AIRBNB</td>\n",
       "      <td>2204.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>AIRBNB</td>\n",
       "      <td>2230.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2024-12-23</td>\n",
       "      <td>PANDA EXPRESS</td>\n",
       "      <td>902.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2019-09-05</td>\n",
       "      <td>COSTCO</td>\n",
       "      <td>953.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2022-12-14</td>\n",
       "      <td>DOORDASH</td>\n",
       "      <td>1402.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2020-04-23</td>\n",
       "      <td>CITY UTILITIES</td>\n",
       "      <td>194.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2020-06-22</td>\n",
       "      <td>SPOTIFY</td>\n",
       "      <td>1111.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023-07-05</td>\n",
       "      <td>LOWE'S</td>\n",
       "      <td>1706.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2019-02-22</td>\n",
       "      <td>WALMART</td>\n",
       "      <td>863.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2020-09-04</td>\n",
       "      <td>TARGET</td>\n",
       "      <td>1349.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2023-08-26</td>\n",
       "      <td>INSTACART</td>\n",
       "      <td>1474.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2025-08-29</td>\n",
       "      <td>LYFT</td>\n",
       "      <td>2096.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2019-11-15</td>\n",
       "      <td>AIRBNB</td>\n",
       "      <td>1089.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2023-07-03</td>\n",
       "      <td>DOORDASH</td>\n",
       "      <td>1888.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2022-01-14</td>\n",
       "      <td>STARBUCKS</td>\n",
       "      <td>1316.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2025-08-25</td>\n",
       "      <td>DOORDASH</td>\n",
       "      <td>774.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2020-12-21</td>\n",
       "      <td>MACY'S</td>\n",
       "      <td>884.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2022-10-17</td>\n",
       "      <td>COSTCO</td>\n",
       "      <td>441.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>MCDONALDS</td>\n",
       "      <td>2006.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2022-05-02</td>\n",
       "      <td>MCDONALDS</td>\n",
       "      <td>1204.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2019-02-13</td>\n",
       "      <td>SPOTIFY</td>\n",
       "      <td>1411.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2022-06-02</td>\n",
       "      <td>APPLE</td>\n",
       "      <td>908.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2022-12-13</td>\n",
       "      <td>NETFLIX</td>\n",
       "      <td>2467.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2025-12-30</td>\n",
       "      <td>SPOTIFY</td>\n",
       "      <td>1312.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>SUSHI HOUSE</td>\n",
       "      <td>1225.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2022-08-10</td>\n",
       "      <td>GOOGLE</td>\n",
       "      <td>2074.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2022-07-26</td>\n",
       "      <td>NETFLIX</td>\n",
       "      <td>800.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>CITY UTILITIES</td>\n",
       "      <td>-89.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2021-07-05</td>\n",
       "      <td>NETFLIX</td>\n",
       "      <td>48.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2023-07-04</td>\n",
       "      <td>BEST BUY</td>\n",
       "      <td>1298.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date        merchant   amount\n",
       "0   2021-09-26          AMAZON     1.00\n",
       "1   2024-08-11       STARBUCKS  2395.00\n",
       "2   2025-01-09          AIRBNB  1053.93\n",
       "3   2019-09-22           SHELL  1698.42\n",
       "4   2020-01-19        DOORDASH  1613.00\n",
       "5   2023-07-06           SHELL  2465.31\n",
       "6   2022-11-26          AMAZON   276.26\n",
       "7   2024-07-04    CAR WASH PRO   311.96\n",
       "8   2023-07-29          GOOGLE   434.00\n",
       "9   2024-07-15        DOORDASH  2036.66\n",
       "10  2021-10-09          TARGET   907.27\n",
       "11  2020-09-14         SPOTIFY  1842.00\n",
       "12  2019-11-03        DOORDASH   482.00\n",
       "13  2024-08-22            LYFT   998.24\n",
       "14  2025-02-08        DOORDASH   470.54\n",
       "15  2023-01-12       INSTACART   775.21\n",
       "16  2021-06-22          TARGET  2249.95\n",
       "17  2022-05-21          AIRBNB  1143.25\n",
       "18  2024-02-12           APPLE  1951.52\n",
       "19  2019-02-06         WALMART   900.87\n",
       "20  2021-03-23          AIRBNB  2204.54\n",
       "21  2022-12-09          AIRBNB  2230.44\n",
       "22  2024-12-23   PANDA EXPRESS   902.63\n",
       "23  2019-09-05          COSTCO   953.19\n",
       "24  2022-12-14        DOORDASH  1402.78\n",
       "25  2020-04-23  CITY UTILITIES   194.92\n",
       "26  2020-06-22         SPOTIFY  1111.24\n",
       "27  2023-07-05          LOWE'S  1706.30\n",
       "28  2019-02-22         WALMART   863.00\n",
       "29  2020-09-04          TARGET  1349.16\n",
       "30  2023-08-26       INSTACART  1474.73\n",
       "31  2025-08-29            LYFT  2096.89\n",
       "32  2019-11-15          AIRBNB  1089.01\n",
       "33  2023-07-03        DOORDASH  1888.00\n",
       "34  2022-01-14       STARBUCKS  1316.00\n",
       "35  2025-08-25        DOORDASH   774.78\n",
       "36  2020-12-21          MACY'S   884.86\n",
       "37  2022-10-17          COSTCO   441.52\n",
       "38  2023-01-31       MCDONALDS  2006.17\n",
       "39  2022-05-02       MCDONALDS  1204.90\n",
       "40  2019-02-13         SPOTIFY  1411.00\n",
       "41  2022-06-02           APPLE   908.47\n",
       "42  2022-12-13         NETFLIX  2467.00\n",
       "43  2025-12-30         SPOTIFY  1312.28\n",
       "44  2025-07-01     SUSHI HOUSE  1225.23\n",
       "45  2022-08-10          GOOGLE  2074.76\n",
       "46  2022-07-26         NETFLIX   800.63\n",
       "47  2020-07-24  CITY UTILITIES   -89.00\n",
       "48  2021-07-05         NETFLIX    48.00\n",
       "49  2023-07-04        BEST BUY  1298.25"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202f4d91-bbda-4d90-bd84-aca33dfef766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1085b854-0241-4a6f-957e-115d0575c6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
